{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15241.383936\n",
      "246.912\n",
      "<numpy.nditer object at 0x000001F3063AD670>\n",
      "()\n",
      "3.26035353777\n",
      "[-0.30406001  3.00298703  1.98268266]\n",
      "<numpy.nditer object at 0x000001F3063AD670>\n",
      "(0,)\n",
      "(1,)\n",
      "(2,)\n",
      "22.9580114633\n",
      "[[ 0.50885058 -4.89237779  1.51633071  4.02717514 -0.95448464]\n",
      " [ 0.20752995  0.93955795  1.06232495  3.2684255  -2.21717114]\n",
      " [-0.59243366  1.03404827  4.02002748  0.22242829  0.96079592]\n",
      " [-1.77194591  0.52658939 -0.97523128  2.7609527  -0.10958953]]\n",
      "<numpy.nditer object at 0x000001F3063AD670>\n",
      "(0, 0)\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(0, 4)\n",
      "(1, 0)\n",
      "(1, 1)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(2, 2)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(3, 0)\n",
      "(3, 1)\n",
      "(3, 2)\n",
      "(3, 3)\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "# First implement a gradient checker by filling in the following functions\n",
    "def gradcheck_naive(f, x):\n",
    "    \"\"\" Gradient check for a function f.\n",
    "\n",
    "    Arguments:\n",
    "    f -- a function that takes a single argument and outputs the\n",
    "         cost and its gradients\n",
    "    x -- the point (numpy array) to check the gradient at\n",
    "    \"\"\"\n",
    "\n",
    "    rndstate = random.getstate()\n",
    "    random.setstate(rndstate)\n",
    "    fx, grad = f(x) # Evaluate function value at original point\n",
    "    h = 1e-4        # Do not change this!\n",
    "    print(fx)\n",
    "    print(grad)\n",
    "    # Iterate over all indexes ix in x to check the gradient.\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    print(it)\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        print(ix)\n",
    "        # Try modifying x[ix] with h defined above to compute numerical\n",
    "        # gradients (numgrad).\n",
    "\n",
    "        # Use the centered difference of the gradient.\n",
    "        # It has smaller asymptotic error than forward / backward difference\n",
    "        # methods. If you are curious, check out here:\n",
    "        # https://math.stackexchange.com/questions/2326181/when-to-use-forward-or-central-difference-approximations\n",
    "\n",
    "        # Make sure you call random.setstate(rndstate)\n",
    "        # before calling f(x) each time. This will make it possible\n",
    "        # to test cost functions with built in randomness later.\n",
    "\n",
    "        ### YOUR CODE HERE:\n",
    "        xt = x[ix]\n",
    "        x[ix] = xt-h\n",
    "        random.setstate(rndstate)\n",
    "        f1,g1 = f(x)\n",
    "        x[ix] = xt+h\n",
    "        random.setstate(rndstate)\n",
    "        f2,g2 = f(x)\n",
    "\n",
    "        numgrad = (f2-f1)/(2*h)\n",
    "        x[ix]=xt\n",
    "        ### END YOUR CODE\n",
    "\n",
    "        # Compare gradients\n",
    "        reldiff = abs(numgrad - grad[ix]) / max(1, abs(numgrad), abs(grad[ix]))\n",
    "        if reldiff > 1e-5:\n",
    "            print(\"Gradient check failed.\")\n",
    "            print(\"First gradient error found at index %s\" % str(ix))\n",
    "            print(\"Your gradient: %f \\t Numerical gradient: %f\" % (\n",
    "                grad[ix], numgrad))\n",
    "            return\n",
    "\n",
    "        it.iternext() # Step to next dimension\n",
    "\n",
    "\n",
    "\n",
    "def sanity_check():\n",
    "    \"\"\"\n",
    "    Some basic sanity checks.\n",
    "    \"\"\"\n",
    "    quad = lambda x: (np.sum(x ** 2), x * 2)\n",
    "\n",
    "    gradcheck_naive(quad, np.array(123.456))      # scalar test\n",
    "    gradcheck_naive(quad, np.random.randn(3,))    # 1-D test\n",
    "    gradcheck_naive(quad, np.random.randn(4,5))   # 2-D test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sanity_check()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad = lambda x: (np.sum(x ** 2), x * 2)\n",
    "quad(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
