{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are using two methods in this competation, FCN and ResNet. \n",
    "\n",
    "## Table of content:\n",
    "    1. Data processing\n",
    "    2. FCN    \n",
    "    3. ResNet\n",
    "    4. Fit model\n",
    "    5. Hyperparameter tunning\n",
    "\n",
    "See detailed steps in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperas\r\n",
      "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.6/site-packages (from hyperas) (5.5.0)\r\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.6/site-packages (from hyperas) (0.1.2)\r\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from hyperas) (0.3)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from hyperas) (2.2.4)\r\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.6/site-packages (from hyperas) (4.4.0)\r\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.6/site-packages (from hyperas) (1.0.0)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (1.4.2)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (4.3.2)\r\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (4.5.0)\r\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (2.10.1)\r\n",
      "Requirement already satisfied: mistune>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (0.8.4)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (3.1.0)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (2.4.2)\r\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (0.6.0)\r\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from nbconvert->hyperas) (0.3.1)\r\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.6/site-packages (from hyperopt->hyperas) (3.8.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from hyperopt->hyperas) (1.2.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt->hyperas) (1.12.0)\r\n",
      "Requirement already satisfied: networkx==2.2 in /opt/conda/lib/python3.6/site-packages (from hyperopt->hyperas) (2.2)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt->hyperas) (0.17.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from hyperopt->hyperas) (4.32.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from hyperopt->hyperas) (1.16.4)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->hyperas) (1.0.8)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->hyperas) (1.1.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras->hyperas) (2.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->hyperas) (5.1.1)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat->hyperas) (3.0.1)\r\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat->hyperas) (0.2.0)\r\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.6/site-packages (from jupyter->hyperas) (4.5.2)\r\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.6/site-packages (from jupyter->hyperas) (7.5.0)\r\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.6/site-packages (from jupyter->hyperas) (5.5.0)\r\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.6/site-packages (from jupyter->hyperas) (6.0.0)\r\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.6/site-packages (from jupyter->hyperas) (5.1.1)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from traitlets>=4.2->nbconvert->hyperas) (4.4.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert->hyperas) (0.5.1)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (19.1.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (0.14.11)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (41.0.1)\r\n",
      "Requirement already satisfied: jupyter-client>=4.1 in /opt/conda/lib/python3.6/site-packages (from qtconsole->jupyter->hyperas) (5.3.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets->jupyter->hyperas) (3.5.0)\r\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.6/site-packages (from ipywidgets->jupyter->hyperas) (7.6.1)\r\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (0.8.2)\r\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (1.5.0)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (18.0.0)\r\n",
      "Requirement already satisfied: tornado>=4 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (5.0.2)\r\n",
      "Requirement already satisfied: prompt_toolkit<2.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from jupyter-console->jupyter->hyperas) (2.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (2.8.0)\r\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (4.7.0)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.1.0)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\r\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.13.3)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt_toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.6.0)\r\n",
      "Requirement already satisfied: parso>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.5.0)\r\n",
      "Installing collected packages: hyperas\r\n",
      "Successfully installed hyperas-0.4.1\r\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.6/site-packages (0.1.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from hyperopt) (4.32.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt) (1.12.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt) (0.17.1)\r\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.6/site-packages (from hyperopt) (3.8.0)\r\n",
      "Requirement already satisfied: networkx==2.2 in /opt/conda/lib/python3.6/site-packages (from hyperopt) (2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from hyperopt) (1.2.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from hyperopt) (1.16.4)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx==2.2->hyperopt) (4.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperas\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv1D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3810, 128, 10) , X_test shape: (3816, 128, 10)\n",
      "Y_train shape: (3810, 9)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "X_train = pd.read_csv('../input/X_train.csv').iloc[:,3:].values.reshape(-1,128,10)\n",
    "X_test  = pd.read_csv('../input/X_test.csv' ).iloc[:,3:].values.reshape(-1,128,10)\n",
    "print('X_train shape:', X_train.shape, ', X_test shape:', X_test.shape)\n",
    "\n",
    "dfy= pd.read_csv('../input/y_train.csv')\n",
    "# Get groups for CV later\n",
    "groups= dfy.iloc[:,1].values\n",
    "Y_train=dfy.iloc[:,-1]\n",
    "# Convert to one-hot for classes\n",
    "num_classes = len(Y_train.unique())\n",
    "Y_train = Y_train.replace(Y_train.unique(),range(num_classes))\n",
    "Y_train = to_categorical(Y_train.values,num_classes)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FCN\n",
    "The FCN used in this work consists of 3 convolutional blocks, each composed by a 1-dimensional convolution followed by a batch normalization layer and a rectified linear unit (ReLU) activation function. The output of the last convolutional block are fed to the GAP layer, to which a traditional softmax is fully connected for the time series classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_FCN(input_shape=X_train.shape[1:], filters=1, kernel_size=1, s=1, units=num_classes):\n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape.\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: none\n",
    "\n",
    "    # CONV -> BN -> RELU Block\n",
    "    X = Conv1D(filters, kernel_size, strides=s)(X_input)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block\n",
    "    X = Conv1D(filters, kernel_size, strides=s)(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block\n",
    "    X = Conv1D(filters, kernel_size, strides=s)(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL - none\n",
    "    \n",
    "    # GAP\n",
    "    X = GlobalAveragePooling1D()(X)\n",
    "    \n",
    "    # FLATTEN - none\n",
    "    \n",
    "    # FULLYCONNECTED\n",
    "    X = Dense(units, activation='softmax',name='d0')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ResNet\n",
    "The ResNet here consists of 3 residual blocks, each composed of three 1-dimensional convolutional layers, and their output is added to input of the residual block. The last residual block, as for the FCN, is followed by a GAP layer and a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ResNet(input_shape=X_train.shape[1:], filters=1, kernel_size=1, s=1, units=num_classes):\n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape.\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: none\n",
    "\n",
    "    # CONV -> BN -> RELU Block\n",
    "    X = Conv1D(filters, kernel_size, strides=s)(X_input)\n",
    "    X = Add()([X,X_input])\n",
    "    \n",
    "    # CONV -> BN -> RELU Block\n",
    "    X = Conv1D(filters, kernel_size, strides=s)(X)\n",
    "    X = Add()([X,X_input])\n",
    "    \n",
    "    # CONV -> BN -> RELU Block\n",
    "    X = Conv1D(filters, kernel_size, strides=s)(X)\n",
    "    X = Add()([X,X_input])\n",
    "\n",
    "    # MAXPOOL - none\n",
    "    \n",
    "    # GAP\n",
    "    X = GlobalAveragePooling1D()(X)\n",
    "    \n",
    "    # FLATTEN - none\n",
    "    \n",
    "    # FULLYCONNECTED\n",
    "    X = Dense(units, activation='softmax',name='d0')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_shape = X_train.shape[1:]\n",
    "filters = 1\n",
    "kernel_size = 1\n",
    "s = 1\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "folds=2\n",
    "model_Name = \"model_FCN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1906 samples, validate on 1904 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 2.2389 - acc: 0.1705 - val_loss: 2.2203 - val_acc: 0.1665\n",
      "Train on 1904 samples, validate on 1906 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 2.1854 - acc: 0.1838 - val_loss: 2.2108 - val_acc: 0.0860\n",
      "Avg loss:  2.2121514128143076 Avg acc:  0.177168847633272\n",
      "Avg val_loss:  2.215553922717824 Avg val_acc:  0.12626783405868203\n"
     ]
    }
   ],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "cvloss = []\n",
    "cvloss_val = []\n",
    "cvacc = []\n",
    "cvacc_val = []\n",
    "gkf = GroupKFold(n_splits=folds)\n",
    "\n",
    "for train_idx,valid_idx in gkf.split(X_train,Y_train,groups=groups):\n",
    "    # Create and compile the FCN model\n",
    "    model = model_FCN(input_shape, filters, kernel_size,s,num_classes) if model_Name is \"model_FCN\" else\\\n",
    "                    model_ResNet(input_shape, filters, kernel_size,s,num_classes)\n",
    "    model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])   \n",
    "    # Fit and evaluate the model\n",
    "    history = model.fit(x=X_train[train_idx],y=Y_train[train_idx],epochs=epochs,\\\n",
    "                            validation_data=(X_train[valid_idx],Y_train[valid_idx]),shuffle=True,verbose=2)\n",
    "    # Update score\n",
    "    cvloss.append(history.history['loss'][-1])\n",
    "    cvloss_val.append(history.history['val_loss'][-1])\n",
    "    cvacc.append(history.history['acc'][-1])\n",
    "    cvacc_val.append(history.history['val_acc'][-1])\n",
    "    \n",
    "    '''\n",
    "    # Plot loss during training\n",
    "    plt.subplot(121)\n",
    "    plt.title('Loss in Fold '+str(f))\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='valid')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy during training\n",
    "    plt.subplot(122)\n",
    "    plt.title('Accuracy in Fold '+str(f))\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='valid')\n",
    "    plt.legend()\n",
    "    plt.show()   \n",
    "    '''\n",
    "    \n",
    "print(\"Avg loss: \", np.mean(cvloss), \"Avg acc: \", np.mean(cvacc))\n",
    "print(\"Avg val_loss: \", np.mean(cvloss_val), \"Avg val_acc: \", np.mean(cvacc_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter tunning\n",
    "We are using hyperas to tune epochs, filters, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    global X_train\n",
    "    global Y_train   \n",
    "    return X_train,Y_train,X_train, Y_train,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    model = model_FCN(filters={{choice([1,2,3,4,5])}})\n",
    "    model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])   \n",
    "    result = model.fit(x=x_train,y=y_train,\\\n",
    "                        batch_size={{choice([64, 128])}},\\\n",
    "                        epochs={{choice([64, 128])}},\\\n",
    "                        validation_split=0.1,shuffle=True,verbose=2)\n",
    "\n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/2019CareerCon_Help_Navigate_Robot.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6367ca9a7c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                       notebook_name='2019CareerCon_Help_Navigate_Robot')\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evalutation of best performing model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./temp_model.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[0;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mnotebook_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/{}.ipynb\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mnotebook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO_CONVERT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mexporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/2019CareerCon_Help_Navigate_Robot.ipynb'"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='2019CareerCon_Help_Navigate_Robot')\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_train, Y_train))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
