{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture notes\n",
    "\n",
    "- Sample size: n\n",
    "- Predictor dim: p\n",
    "- Class numbers: k\n",
    "\n",
    "\n",
    "1. Logistic regression\n",
    "- logistic function p(X)\n",
    "- log-odds (logit) is linear in X\n",
    "- likelihood function: finding coefficients that maximize it. Number of coeff depends on predictor dim\n",
    "- z-stats\n",
    "\n",
    "2. Multiple logistic regression\n",
    "\n",
    "3. Discriminant analysis\n",
    "- Bayes' theorem\n",
    "- posterior prob. p_k(x) depends on pi_k (prior prob., easy to compute from Y), and f_k(x) (desity function of X, hard to get from X, but can assume simple forms)\n",
    "- when p=1\n",
    "    - assume f_k(x,mu_k,sigma) are Gaussian with the same variance\n",
    "    - the max of p_k(x) in k <=> the max of discriminant functions in k that is linear in x, which still depends on mu_k, sigma and pi_k\n",
    "    - need estimate pi_k, mu_k and sigma from X and Y\n",
    "    - Set pairs of discriminant functions equal to each other to determine Bayes decision boundary\n",
    "    - Once have k for given x, we can compute p_k(x) for the probability\n",
    "- when p>1\n",
    "    - assume f_k(x,mu_k,Sigma) are Gaussian with the same covariance\n",
    "    - algorithm same as p=1 case\n",
    "- Forms of discriminant analysis\n",
    "    - Linear: f_k(x) are Gaussian having the same covariance\n",
    "    - Quatratic: f_k(x) are Gaussian having different covariance\n",
    "    - Naive Bayes: X are independent in each class (covariance matrix is diagonal); useful for large p; useful for mixed feature vectors\n",
    "\n",
    "4. Evaluate threshold value\n",
    "- Confusion matrix\n",
    "- True/False positive/negative\n",
    "- Two types of error: True/False postitive rates\n",
    "- The Total Error is a weighted average of the False Positive Rate and False Negative Rate. The weights are determined by the Prior Probabilities of Positive and Negative Responses.\n",
    "- Visual method: ROC+AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets,preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Smarket.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "0  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "1  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "3  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "4  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691034\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Direction[Down]   No. Observations:                 1250\n",
      "Model:                          Logit   Df Residuals:                     1243\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Mon, 05 Feb 2018   Pseudo R-squ.:                0.002074\n",
      "Time:                        11:37:05   Log-Likelihood:                -863.79\n",
      "converged:                       True   LL-Null:                       -865.59\n",
      "                                        LLR p-value:                    0.7319\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1260      0.241      0.523      0.601        -0.346     0.598\n",
      "Lag1           0.0731      0.050      1.457      0.145        -0.025     0.171\n",
      "Lag2           0.0423      0.050      0.845      0.398        -0.056     0.140\n",
      "Lag3          -0.0111      0.050     -0.222      0.824        -0.109     0.087\n",
      "Lag4          -0.0094      0.050     -0.187      0.851        -0.107     0.089\n",
      "Lag5          -0.0103      0.050     -0.208      0.835        -0.107     0.087\n",
      "Volume        -0.1354      0.158     -0.855      0.392        -0.446     0.175\n",
      "==============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[507, 141],\n",
       "       [457, 145]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression - statsmodels\n",
    "# create training data and factorize classes, add intercept column to X\n",
    "y,X = dmatrices('Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume',data,return_type='dataframe')\n",
    "Y = y.iloc[:,0]\n",
    "lm1 = sm.Logit(Y,X).fit()\n",
    "print(lm1.summary())\n",
    "# determine class with threshold = 0.5\n",
    "threshold = 0.5\n",
    "pre_label = pd.DataFrame(np.zeros((len(lm1.predict()),1)),columns=['label'])\n",
    "pre_label[lm1.predict()>threshold] =1\n",
    "confusion_matrix(Y,pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[513 459]\n",
      " [135 143]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression - sklearn\n",
    "Y = data.Direction.factorize()[0]\n",
    "X = data.iloc[:,1:7]\n",
    "lm2 = LogisticRegression()\n",
    "lm2.fit(X,y)\n",
    "print(confusion_matrix(lm2.predict(X),Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[507 457]\n",
      " [141 145]]\n"
     ]
    }
   ],
   "source": [
    "# LDA - sklearn\n",
    "Y = data.Direction.factorize()[0]\n",
    "X = data.iloc[:,1:7]\n",
    "ldam = LDA()\n",
    "ldam.fit(X,Y)\n",
    "print(confusion_matrix(ldam.predict(X),Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[512 421]\n",
      " [136 181]]\n"
     ]
    }
   ],
   "source": [
    "# QDA - sklearn\n",
    "Y = data.Direction.factorize()[0]\n",
    "X = data.iloc[:,1:7]\n",
    "qdam = QDA()\n",
    "qdam.fit(X,Y)\n",
    "print(confusion_matrix(qdam.predict(X),Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[501 157]\n",
      " [147 445]]\n"
     ]
    }
   ],
   "source": [
    "# KNN - sklearn\n",
    "Y = data.Direction.factorize()[0]\n",
    "X = data.iloc[:,1:7]\n",
    "knnm = KNN(n_neighbors=3)\n",
    "knnm.fit(X,Y)\n",
    "print(confusion_matrix(knnm.predict(X),Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
