{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture notes\n",
    "\n",
    "- Tree: T\n",
    "- Num of nodes: |T|\n",
    "- terminal node, internal node\n",
    "\n",
    "1. Regression Tree\n",
    "- Find boxes R1...Rj minimizing RSS (RSS depends on the mean of Y in each box)\n",
    "- Recursive binary splitting\n",
    "    - Find Rj, Xi and s minimizing RSS\n",
    "    - Only split one region at a time\n",
    "    - Stopping criterion: num of observations in each region\n",
    "- Tree pruning\n",
    "    - Cost complexity pruning (weakest link pruning)\n",
    "        - Use recursive binary splitting to grow a large tree T0\n",
    "        - Find the subtree T minimizing RSS+Penalty, where Penaly = alpha * |T|\n",
    "    - Use CV to determine the best tuning parameter alpha\n",
    "\n",
    "2. Classification Tree\n",
    "- algorithm is the same as regression tree\n",
    "- instead of RSS, algorithm minimizes Gini index or Cross Entropy\n",
    "\n",
    "3. Bagging\n",
    "- A method to reduce the variance of the model\n",
    "- Bootstrap creating B samples with replacement. For each sample, grow a large tree. \n",
    "- Use all trees to predict by taking the average (for regression) or majority vote (for classification)\n",
    "- Out-of-bag (OOB) error estimation\n",
    "    - One observation is only visible for 2/3 of the bagging (banefit from bootstrap). Use the left 1/3 trees to estimate the prediction error\n",
    "    - For large B, OOB is equivalent to LOO CV\n",
    "    - OOB to determine the best B\n",
    "- Variable importance: record the total decrease of RSS or Gini index due to splits over a given predictor, then average over all B trees. Large value indicates important variable.\n",
    "\n",
    "3. Random forests\n",
    "- A random sample of m=sqrt(p) predictors is used for splitting in bagging\n",
    "- Decorrelates trees by avoiding dominant predictor in the top split\n",
    "\n",
    "4. Boosting\n",
    "- Trees are grown sequentially, i.e., each tree is grown using info from previous trees, and with modified response Y\n",
    "- Learn slowly: improve the model in areas where it does not perform well\n",
    "- Tuning parameters:\n",
    "    - The number of tree B (use CV)\n",
    "    - The shrinkage parameter lambda (0.01 or 0.001)\n",
    "    - The num of splits d (1 works well)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
