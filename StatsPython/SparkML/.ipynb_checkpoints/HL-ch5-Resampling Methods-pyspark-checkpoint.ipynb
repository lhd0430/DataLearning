{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture Notes:\n",
    "\n",
    "- Num of sample partition: K\n",
    "\n",
    "1. Cross-validation\n",
    "- Bias-Variance trade off\n",
    "- for prediction error estimation\n",
    "- CV for regression\n",
    "    - Estimate CV(K), which is the average of all MSE_k\n",
    "- CV for classification\n",
    "    - Estimate CV(K), which is the average of all Err_k (error rate)\n",
    "- for determining the best parameter\n",
    "\n",
    "2. Bootstrap\n",
    "- Resampling with replacements\n",
    "- for SE estimation, not good for prediction erorr estimation\n",
    "- bootstrap confidence interval\n",
    "    - resampling 1000 times from originial data\n",
    "    - build model for each sample and compute RSE/MSE\n",
    "    - compute the mean and std of the set of 1000 RSE/MSE\n",
    "    - or use 95% threshold to get lower and upper bound of the set of 1000 RSE/MSE, i.e. 2.5-97.5 percentile of the set\n",
    "- Pr(one observation is not in the boostrap) = (1-1/n)^n (around 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import findspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, DataFrame, DataFrameReader\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# change the path on your machine\n",
    "findspark.init(\"/Users/lhd0430/Downloads/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creat spark session\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n",
      "1250\n"
     ]
    }
   ],
   "source": [
    "# Load data as pyspark.sql.DataFrame\n",
    "data = spark.read.csv(\"../data/Smarket.csv\", header=True, inferSchema=True)\n",
    "data.cache()\n",
    "print(data.count())\n",
    "data.dropna()\n",
    "print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.replace(['Up','Down'],['1','0'],'Direction')\n",
    "data = data.withColumn('Direction',data[\"Direction\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5512258520979454\n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "\n",
    "# Convert feature to vector type\n",
    "vecAssembler = VectorAssembler(inputCols=data.columns[:-2], outputCol=\"features\")\n",
    "df = vecAssembler.transform(data)\n",
    "\n",
    "# Fit cv model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Direction\")\n",
    "evaAUR = BinaryClassificationEvaluator(labelCol=\"Direction\",metricName=\"areaUnderROC\")\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "cv = CrossValidator(estimator=lr, evaluator=evaAUR, numFolds=3, estimatorParamMaps=paramGrid)\n",
    "ml = cv.fit(df)\n",
    "print(ml.avgMetrics[0])\n",
    "# Note: CrossValidator is similar to sklearn GridSearchCV. It requires estimator,evaluator, and the grid of tuning parameters.\n",
    "\n",
    "# Predict\n",
    "predict = ml.transform(df)\n",
    "\n",
    "# Evaluate\n",
    "evaAUR = BinaryClassificationEvaluator(labelCol=\"Direction\",metricName=\"areaUnderROC\")\n",
    "aur = evaAUR.evaluate(predict)\n",
    "print(aur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553814246093 0.0150243990288\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap\n",
    "n_iter = 10\n",
    "stats = list()\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Direction\")\n",
    "evaAUR = BinaryClassificationEvaluator(labelCol=\"Direction\",metricName=\"areaUnderROC\")\n",
    "for i in range(n_iter):\n",
    "    df_resample = df.sample(withReplacement=True,fraction=1.0)\n",
    "    ml = lr.fit(df_resample)\n",
    "    predict = ml.transform(df_resample)\n",
    "    aur = evaAUR.evaluate(predict)\n",
    "    stats.append(aur)\n",
    "print(np.mean(stats),np.std(stats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
