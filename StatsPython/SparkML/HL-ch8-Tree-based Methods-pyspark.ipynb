{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture notes\n",
    "\n",
    "- Tree: T\n",
    "- Num of nodes: |T|\n",
    "- terminal node, internal node\n",
    "\n",
    "1. Regression Tree\n",
    "- Find boxes R1...Rj minimizing RSS (RSS depends on the mean of Y in each box)\n",
    "- Recursive binary splitting\n",
    "    - Find Rj, Xi and s minimizing RSS\n",
    "    - Only split one region at a time\n",
    "    - Stopping criterion: num of observations in each region\n",
    "    - This is a greedy method, as the best split is made at each step rather than leading to a better split in the future. (like forward feature selection)\n",
    "- Tree pruning\n",
    "    - Cost complexity pruning (weakest link pruning)\n",
    "        - Use recursive binary splitting to grow a large tree T0\n",
    "        - Find the subtree T minimizing RSS+Penalty, where Penaly = alpha * |T|\n",
    "    - Use CV to determine the best tuning parameter alpha\n",
    "\n",
    "2. Classification Tree\n",
    "- algorithm is the same as regression tree\n",
    "- instead of RSS, algorithm minimizes Gini index or Cross Entropy\n",
    "\n",
    "3. Bagging\n",
    "- A method to reduce the variance of the model\n",
    "- Bootstrap creating B samples with replacement. For each sample, grow a large tree. \n",
    "- Use all trees to predict by taking the average (for regression) or majority vote (for classification)\n",
    "- Out-of-bag (OOB) error estimation\n",
    "    - One observation is only visible for 2/3 of the bagging (banefit from bootstrap). Use the left 1/3 trees to estimate the prediction error\n",
    "    - For large B, OOB is equivalent to LOO CV\n",
    "    - OOB to determine the best B\n",
    "- Variable importance: record the total decrease of RSS or Gini index due to splits over a given predictor, then average over all B trees. Large value indicates important variable.\n",
    "\n",
    "3. Random forests\n",
    "- A random sample of m=sqrt(p) predictors is used for splitting in bagging\n",
    "- Decorrelates trees by avoiding dominant predictor in the top split\n",
    "- Tuning parameters:\n",
    "    - tree num B\n",
    "    - predictor num m\n",
    "\n",
    "4. Boosting\n",
    "- Trees are grown sequentially, i.e., each tree is grown using info from previous trees, and with modified response Y\n",
    "- Learn slowly: improve the model in areas where it does not perform well\n",
    "- Tuning parameters:\n",
    "    - The number of tree B (use CV)\n",
    "    - The shrinkage parameter lambda (0.01 or 0.001)\n",
    "    - The num of splits d (1 works well)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import findspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, DataFrame, DataFrameReader\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorSlicer, StandardScaler, PCA\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
    "import itertools\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# change the path on your machine\n",
    "findspark.init(\"/Users/lhd0430/Downloads/spark\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creat spark session\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "# Classification tree\n",
    "\n",
    "# Load data as pyspark.sql.DataFrame\n",
    "data = spark.read.csv(\"../data/Carseats.csv\", header=True, inferSchema=True)\n",
    "data.cache()\n",
    "print(data.count())\n",
    "data = data.dropna()\n",
    "print(data.count())\n",
    "# Convert string to index\n",
    "data = data.withColumn(\"High\", when(data[\"Sales\"]>8,1).otherwise(0))\n",
    "data = data.drop(\"Sales\")\n",
    "catColumns = [\"ShelveLoc\",\"Urban\",\"US\"]\n",
    "for i in catColumns:\n",
    "    indexer = StringIndexer(inputCol=i, outputCol=i+\"Indexed\")\n",
    "    model = indexer.fit(data)\n",
    "    data = model.transform(data)\n",
    "    data = data.drop(i)\n",
    "# Convert feature to vector type\n",
    "featureCol = data.columns\n",
    "featureCol.remove('High')\n",
    "vecAssembler = VectorAssembler(inputCols=featureCol, outputCol=\"features\")\n",
    "df = vecAssembler.transform(data)\n",
    "df.show(5)\n",
    "# Split train and test\n",
    "(train, test) = df.randomSplit([0.8, 0.2])\n",
    "# Fit\n",
    "ctree = DecisionTreeClassifier(labelCol=\"High\",featuresCol=\"features\")\n",
    "ml = ctree.fit(train)\n",
    "# Predict\n",
    "predict = ml.transform(test)\n",
    "# Evaluate\n",
    "evaAUR = BinaryClassificationEvaluator(labelCol=\"High\",metricName=\"areaUnderROC\")\n",
    "aur = evaAUR.evaluate(predict)\n",
    "print(aur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm|  age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185| 61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147| 54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
      "|0.02985| 0.0| 2.18|   0|0.458| 6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5| 7.87|   0|0.524|6.012| 66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87|   0|0.524|5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5| 7.87|   0|0.524|6.004| 85.9|6.5921|  5|311|   15.2|386.71| 17.1|18.9|\n",
      "|0.22489|12.5| 7.87|   0|0.524|6.377| 94.3|6.3467|  5|311|   15.2|392.52|20.45|15.0|\n",
      "|0.11747|12.5| 7.87|   0|0.524|6.009| 82.9|6.2267|  5|311|   15.2| 396.9|13.27|18.9|\n",
      "|0.09378|12.5| 7.87|   0|0.524|5.889| 39.0|5.4509|  5|311|   15.2| 390.5|15.71|21.7|\n",
      "|0.62976| 0.0| 8.14|   0|0.538|5.949| 61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|\n",
      "|0.63796| 0.0| 8.14|   0|0.538|6.096| 84.5|4.4619|  4|307|   21.0|380.02|10.26|18.2|\n",
      "|0.62739| 0.0| 8.14|   0|0.538|5.834| 56.5|4.4986|  4|307|   21.0|395.62| 8.47|19.9|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|5.935| 29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|\n",
      "| 0.7842| 0.0| 8.14|   0|0.538| 5.99| 81.7|4.2579|  4|307|   21.0|386.75|14.67|17.5|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|5.456| 36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|\n",
      "| 0.7258| 0.0| 8.14|   0|0.538|5.727| 69.5|3.7965|  4|307|   21.0|390.95|11.28|18.2|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"../data/Boston.csv\", header=True, inferSchema=True)\n",
    "data.cache()\n",
    "print(data.count())\n",
    "data = data.dropna()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "506\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|            features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[0.00632,18.0,2.3...|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[0.02731,0.0,7.07...|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|[0.02729,0.0,7.07...|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|[0.03237,0.0,2.18...|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|[0.06905,0.0,2.18...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "12.527425080463873\n",
      "50.739567497881396\n",
      "dict_items([(Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'), False), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'), 10), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='featuresCol', doc='features column name'), 'features'), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'), 'variance'), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='labelCol', doc='label column name'), 'medv'), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'), 32), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'), 4), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'), 256), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'), 0.0), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'), 1), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='predictionCol', doc='prediction column name'), 'prediction'), (Param(parent='DecisionTreeRegressor_4d0594a79cbec58b2268', name='seed', doc='random seed'), -5267648402372675916)])\n"
     ]
    }
   ],
   "source": [
    "# Regression tree\n",
    "\n",
    "# Load data as pyspark.sql.DataFrame\n",
    "data = spark.read.csv(\"../data/Boston.csv\", header=True, inferSchema=True)\n",
    "data.cache()\n",
    "print(data.count())\n",
    "data = data.dropna()\n",
    "print(data.count())\n",
    "# Convert feature to vector type\n",
    "featureCol = data.columns\n",
    "featureCol.remove('medv')\n",
    "vecAssembler = VectorAssembler(inputCols=featureCol, outputCol=\"features\")\n",
    "df = vecAssembler.transform(data)\n",
    "df.show(5)\n",
    "# Split train and test\n",
    "(train, test) = df.randomSplit([0.8, 0.2])\n",
    "# Fit\n",
    "rtree = DecisionTreeRegressor(labelCol=\"medv\",featuresCol=\"features\")\n",
    "ml = rtree.fit(train)\n",
    "# Predict\n",
    "predict = ml.transform(test)\n",
    "# Evaluate\n",
    "evaMSE = RegressionEvaluator(labelCol=\"medv\",metricName=\"mse\")\n",
    "mse = evaMSE.evaluate(predict)\n",
    "print(mse)\n",
    "\n",
    "\n",
    "# CV for best depth\n",
    "paramGrid = ParamGridBuilder().addGrid(rtree.maxDepth, range(1,6)).build()\n",
    "cv = CrossValidator(estimator=rtree, evaluator=evaMSE, numFolds=3, estimatorParamMaps=paramGrid)\n",
    "ml = cv.fit(df)\n",
    "print(ml.avgMetrics[0])\n",
    "print(ml.bestModel.extractParamMap().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "506\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|            features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[0.00632,18.0,2.3...|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[0.02731,0.0,7.07...|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|[0.02729,0.0,7.07...|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|[0.03237,0.0,2.18...|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|[0.06905,0.0,2.18...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "21.623563377403748\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6v8D8XV3Q15N1T0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1164b22e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.739567497881396\n",
      "dict_items([(Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'), False), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'), 10), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'), 'auto'), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='featuresCol', doc='features column name'), 'features'), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'), 'variance'), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='labelCol', doc='label column name'), 'medv'), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'), 32), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'), 2), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'), 256), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'), 0.0), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'), 1), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='numTrees', doc='Number of trees to train (>= 1)'), 3), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='predictionCol', doc='prediction column name'), 'prediction'), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='seed', doc='random seed'), 6420039670846048999), (Param(parent='RandomForestRegressor_4ba3ae14414c91ad04b4', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'), 1.0)])\n"
     ]
    }
   ],
   "source": [
    "# Random forests - regression\n",
    "# if m=p then this is equivalent to bagging\n",
    "\n",
    "# Load data as pyspark.sql.DataFrame\n",
    "data = spark.read.csv(\"../data/Boston.csv\", header=True, inferSchema=True)\n",
    "data.cache()\n",
    "print(data.count())\n",
    "data = data.dropna()\n",
    "print(data.count())\n",
    "# Convert feature to vector type\n",
    "featureCol = data.columns\n",
    "featureCol.remove('medv')\n",
    "vecAssembler = VectorAssembler(inputCols=featureCol, outputCol=\"features\")\n",
    "df = vecAssembler.transform(data)\n",
    "df.show(5)\n",
    "# Fit\n",
    "rand_rtree = RandomForestRegressor(labelCol=\"medv\",maxDepth=2,numTrees=10)\n",
    "ml = rand_rtree.fit(df)\n",
    "# Predict\n",
    "predict = ml.transform(df)\n",
    "# Evaluate\n",
    "evaMSE = RegressionEvaluator(labelCol=\"medv\",metricName=\"mse\")\n",
    "mse = evaMSE.evaluate(predict)\n",
    "print(mse)\n",
    "\n",
    "# Feature importance\n",
    "fimp = pd.DataFrame({\"Importance\":ml.featureImportances.toArray()*100}, index=featureCol)\n",
    "fig,ax = plt.subplots()\n",
    "ax.barh(np.arange(1,14),width = fimp.sort_values(by=\"Importance\").Importance,align='center')\n",
    "ax.set_yticks(np.arange(1,14,1))\n",
    "ax.set_yticklabels(fimp.sort_values(by=\"Importance\").index)\n",
    "plt.show()\n",
    "\n",
    "# GridSearchCV to determine the best num of features and num B (can apply this to other tuning parameters)\n",
    "paramGrid = ParamGridBuilder().addGrid(rand_rtree.maxDepth, range(1,3)).addGrid(rand_rtree.numTrees,range(1,5)).build()\n",
    "cv = CrossValidator(estimator=rand_rtree, evaluator=evaMSE, numFolds=3, estimatorParamMaps=paramGrid)\n",
    "mlcv = cv.fit(df)\n",
    "print(mlcv.avgMetrics[0])\n",
    "print(mlcv.bestModel.extractParamMap().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "506\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|            features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[0.00632,18.0,2.3...|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[0.02731,0.0,7.07...|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|[0.02729,0.0,7.07...|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|[0.03237,0.0,2.18...|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|[0.06905,0.0,2.18...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "26.831105021403626\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKxlNtGMmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11668dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.797625314154146\n",
      "dict_items([(Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'), False), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'), 10), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='featuresCol', doc='features column name'), 'features'), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'), 'variance'), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='labelCol', doc='label column name'), 'medv'), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='lossType', doc='Loss function which GBT tries to minimize (case-insensitive). Supported options: squared, absolute'), 'squared'), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'), 32), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'), 2), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='maxIter', doc='maximum number of iterations (>= 0)'), 3), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'), 256), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'), 0.0), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'), 1), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='predictionCol', doc='prediction column name'), 'prediction'), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='seed', doc='random seed'), 6057059121600367995), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'), 0.001), (Param(parent='GBTRegressor_4b9ab83307d7e75fac5d', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'), 1.0)])\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "\n",
    "# Load data as pyspark.sql.DataFrame\n",
    "data = spark.read.csv(\"../data/Boston.csv\", header=True, inferSchema=True)\n",
    "data.cache()\n",
    "print(data.count())\n",
    "data = data.dropna()\n",
    "print(data.count())\n",
    "# Convert feature to vector type\n",
    "featureCol = data.columns\n",
    "featureCol.remove('medv')\n",
    "vecAssembler = VectorAssembler(inputCols=featureCol, outputCol=\"features\")\n",
    "df = vecAssembler.transform(data)\n",
    "df.show(5)\n",
    "# Fit\n",
    "boost_rtree = GBTRegressor(labelCol=\"medv\",maxDepth=2, stepSize=0.001,maxIter=10) # maxIter = tree num\n",
    "ml = boost_rtree.fit(df)\n",
    "# Predict\n",
    "predict = ml.transform(df)\n",
    "# Evaluate\n",
    "evaMSE = RegressionEvaluator(labelCol=\"medv\",metricName=\"mse\")\n",
    "mse = evaMSE.evaluate(predict)\n",
    "print(mse)\n",
    "\n",
    "# Feature importance\n",
    "fimp = pd.DataFrame({\"Importance\":ml.featureImportances.toArray()*100}, index=featureCol)\n",
    "fig,ax = plt.subplots()\n",
    "ax.barh(np.arange(1,14),width = fimp.sort_values(by=\"Importance\").Importance,align='center')\n",
    "ax.set_yticks(np.arange(1,14,1))\n",
    "ax.set_yticklabels(fimp.sort_values(by=\"Importance\").index)\n",
    "plt.show()\n",
    "\n",
    "# GridSearchCV to determine the best num of features and num B (can apply this to other tuning parameters)\n",
    "paramGrid = ParamGridBuilder().addGrid(rand_rtree.maxDepth, range(1,3)).build()\n",
    "cv = CrossValidator(estimator=boost_rtree, evaluator=evaMSE, numFolds=3, estimatorParamMaps=paramGrid)\n",
    "mlcv = cv.fit(df)\n",
    "print(mlcv.avgMetrics[0])\n",
    "print(mlcv.bestModel.extractParamMap().items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
